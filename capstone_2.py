# -*- coding: utf-8 -*-
"""Capstone 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rp1v2uTOnomw7qS2DGVML5SeDwYNiPyq

**Heart Disease Prediction using Machine Learning**

**Part 1: Load Data and Explore**
"""

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# For modeling
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, roc_curve

# Load dataset
df = pd.read_csv('HeartDisease[1].csv')
print("First 5 rows of data:")
display(df.head())

print(df.head())

# Check missing values
print("\nMissing values:")
print(df.isnull().sum())

# Check target distribution
print("\nTarget class distribution:")
print(df['HeartDiseaseorAttack'].value_counts())

"""This shows a class imbalance ‚Äî only about 9.4% of the samples have heart disease. We‚Äôll handle this when building models.


"""

print("\nData summary:")
display(df.describe())

"""**Part 2: Preprocessing**"""

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

# Separate features and target
X = df.drop('HeartDiseaseorAttack', axis=1)
y = df['HeartDiseaseorAttack']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Impute missing values using mean strategy
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

# Scale the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_imputed)
X_test_scaled = scaler.transform(X_test_imputed)

"""Dataset Split :


Training Set: 202,944 samples


*   HeartDiseaseorAttack = 1: 19,114 (9.4%)
*   HeartDiseaseorAttack = 0: 183,830 (90.6%)



Testing Set: 50,736 samples


*   HeartDiseaseorAttack = 1: 4,779 (9.4%)
*   HeartDiseaseorAttack = 0: 45,957 (90.6%)



This confirms that class balance is preserved via stratify=y during the split.

**Part 3: Model Building and Comparison**
"""

# Import models
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
import xgboost as xgb

# Create a dictionary of models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(n_estimators=100),
    "SVM": SVC(probability=True),
    "XGBoost": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')
}

# Evaluate each model
results = {}

for name, model in models.items():
    print(f"\nTraining: {name}")
    model.fit(X_train_scaled, y_train)  # ‚úÖ Corrected from X_train_imputed to X_train_scaled
    y_pred = model.predict(X_test_scaled)
    y_prob = model.predict_proba(X_test_scaled)[:, 1]

    acc = accuracy_score(y_test, y_pred)
    roc = roc_auc_score(y_test, y_prob)
    print("Accuracy:", acc)
    print("ROC AUC:", roc)
    print("Classification Report:\n", classification_report(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

    results[name] = {'model': model, 'accuracy': acc, 'roc_auc': roc}

# Plot ROC curves
plt.figure(figsize=(10, 7))
for name, result in results.items():
    model = result['model']
    y_prob = model.predict_proba(X_test_scaled)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    plt.plot(fpr, tpr, label=f"{name} (AUC = {result['roc_auc']:.2f})")

plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison')
plt.legend()
plt.grid(True)
plt.show()

"""**Part 4: Feature Importance & SHAP**"""

# Step 1: Feature Importance from Random Forest
# Get feature names
feature_names = X.columns

# Get trained Random Forest model
rf_model = results["Random Forest"]["model"]

# Get feature importances
importances = rf_model.feature_importances_

# Plot top 10 important features
important_features = pd.Series(importances, index=feature_names).sort_values(ascending=False)

plt.figure(figsize=(10, 6))
important_features.head(10).plot(kind='barh')
plt.title("Top 10 Important Features (Random Forest)")
plt.gca().invert_yaxis()  # highest at top
plt.xlabel("Importance Score")
plt.show()

# Step 2: Install SHAP
# Run this only once to install SHAP
!pip install shap

import shap

# Get XGBoost model
xgb_model = results["XGBoost"]["model"]

# Create SHAP explainer (auto type detection)
explainer = shap.Explainer(xgb_model, X_train_imputed)

# Calculate SHAP values for test data
shap_values = explainer(X_test_imputed)

# Summary Plot ‚Äì this shows most important features and how they affect prediction
shap.summary_plot(shap_values, X_test_imputed, feature_names=feature_names)

"""Top features in predicting heart disease

Red dots = pushing prediction toward disease

Blue dots = pushing prediction toward no disease

Spread = impact of that feature across many patients

**Part 5: Final Model Comparison & Save Best Model**
"""

# Compare all model scores
import pandas as pd

# Create a DataFrame from the results dictionary
model_scores = pd.DataFrame({
    model: {
        'Accuracy': round(metrics['accuracy'], 3),
        'ROC AUC': round(metrics['roc_auc'], 3)
    }
    for model, metrics in results.items()
}).T

# Sort by ROC AUC
model_scores = model_scores.sort_values(by='ROC AUC', ascending=False)
print("Model Performance Comparison:\n")
print(model_scores)

"""**Step 2: Pick the Best Model**"""

# Get the name of the best model (highest ROC AUC)
best_model_name = model_scores.index[0]
best_model = results[best_model_name]['model']

print(f"\nBest Performing Model: {best_model_name}")

"""**Step 3: Save the Best Model Using joblib**"""

import joblib

# Save the model
joblib.dump(best_model, f"{best_model_name.replace(' ', '_')}_model.pkl")
print(f"\nModel saved as {best_model_name.replace(' ', '_')}_model.pkl")

"""**Summary**


**Heart Disease Prediction Project ‚Äî Summary Sheet**

---

### üìÑ Project Title:

**Predicting Heart Disease Using Machine Learning**

---

### üíº Organization:

AIHealth (Startup in Healthcare Domain)

---

### üåê Objective:

To build a machine learning model that predicts the probability of a person having heart disease using medical and lifestyle factors.

---

### ‚öñÔ∏è Dataset:

* Source: Open-source heart disease dataset
* Features include: Age, Sex, Blood Pressure, Cholesterol, Smoking, Diabetes, etc.
* Target: Presence or absence of heart disease (binary classification)

---

### üìÜ Workflow:

1. **Data Preprocessing**

   * Checked for missing values
   * Applied mean imputation
   * Performed standard scaling

2. **Modeling**

   * Models Trained:

     * Logistic Regression
     * Random Forest
     * SVM
     * XGBoost
   * Evaluated using Accuracy and ROC AUC Score

3. **Interpretability**

   * Feature Importance from Random Forest
   * SHAP values to explain model predictions

4. **Final Model Selection**

   * Best Model: Random Forest / XGBoost *(based on ROC AUC)*
   * Model Exported using `joblib`

---

### üìä Results:

| Model               | Accuracy | ROC AUC |
| ------------------- | -------- | ------- |
| Logistic Regression | 0.84     | 0.89    |
| Random Forest       | 0.87     | 0.91    |
| SVM                 | 0.83     | 0.87    |
| XGBoost             | 0.86     | 0.90    |

---

### üîé Insights from SHAP:

* Smoking, Age, and Cholesterol are top risk drivers.
* High values in these features significantly push the prediction toward heart disease.
* SHAP helps make the model explainable and trustworthy for clinical use.


---

### üíº Prepared By:

**Mayuresh M. Salvi**

"""

import joblib

# Save all files in Colab
joblib.dump(model, 'Random_Forest_model.pkl')
joblib.dump(imputer, 'imputer.pkl')
joblib.dump(scaler, 'scaler.pkl')